{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "matmul_sol.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOM1YeCo2HJe+mRj+P6w4gF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/domeano/Thermo-and-Fluid-Engineering-Lab/blob/master/matmul_sol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_WTyNWaCi4F",
        "outputId": "7f7e6937-bf65-401c-a8a1-f94c3af61d1f"
      },
      "source": [
        "%%writefile matrix_mul_gpu.cu\r\n",
        "#include<stdio.h>\r\n",
        "#include<math.h>\r\n",
        "#include<stdlib.h>\r\n",
        "\r\n",
        "\r\n",
        "__global__ void matrix_mul_gpu(int* A, int* B, int* result, int N)\r\n",
        "{ \r\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y; \r\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\r\n",
        "    int sum = 0;\r\n",
        "    if( col < N && row < N) \r\n",
        "    {\r\n",
        "        for(int i = 0; i < N; i++) \r\n",
        "        {\r\n",
        "            sum += A[row * N + i] * B[i * N + col];\r\n",
        "        }\r\n",
        "        result[row * N + col] = sum;\r\n",
        "    }\r\n",
        "} \r\n",
        "\r\n",
        "void matrix_mul_cpu(int* A, int* B, int* result, int N)\r\n",
        "{\r\n",
        "    for(int i=0;i<N;i++)\r\n",
        "    {\r\n",
        "        for(int j=0;j<N;j++)\r\n",
        "        {\r\n",
        "            int sum = 0;\r\n",
        "            for (int h = 0; h < N; ++h) \r\n",
        "            {\r\n",
        "                sum += A[i * N + h] * B[h * N + j];\r\n",
        "            }\r\n",
        "            result[i * N + j] = sum;\r\n",
        "        }\r\n",
        "    }\r\n",
        "}\r\n",
        "\r\n",
        "void Init(int* A, int* B, int* result_cpu, int* result_gpu, int N)\r\n",
        "{\r\n",
        "\tfor (int i = 0; i < N; i++)\r\n",
        "  {\r\n",
        "      for(int j=0;j<N;j++)\r\n",
        "      {\r\n",
        "          A[i*N + j]=1;\r\n",
        "          B[i*N + j]=1;\r\n",
        "          result_cpu[i*N + j]=0;\r\n",
        "          result_gpu[i*N + j]=0;\r\n",
        "      }\r\n",
        "  }\r\n",
        "}\r\n",
        "\r\n",
        "int main()\r\n",
        "{\r\n",
        "    int N = 1000;\r\n",
        "    int *A, *B, *result_cpu, *result_gpu;\r\n",
        "    bool chk=false;\r\n",
        "    const int size = (N*N) * sizeof(int);\r\n",
        "    int deviceId;\r\n",
        "    float gpu_time_ms, cpu_time_ms;\r\n",
        "    cudaEvent_t start, stop;\r\n",
        "    cudaEventCreate(&start);\r\n",
        "    cudaEventCreate(&stop);\r\n",
        " \r\n",
        "    cudaGetDevice(&deviceId);\r\n",
        " \r\n",
        "    cudaMallocManaged(&A, size);\r\n",
        "    cudaMallocManaged(&B, size);\r\n",
        "    cudaMallocManaged(&result_gpu, size);\r\n",
        "    result_cpu = (int*)malloc(size);\r\n",
        "\r\n",
        "    cudaMemPrefetchAsync(A, size, cudaCpuDeviceId);\r\n",
        "    cudaMemPrefetchAsync(B, size, cudaCpuDeviceId);\r\n",
        "\r\n",
        "    Init(A,B,result_cpu, result_gpu,N);\r\n",
        "    \r\n",
        "    cudaEventRecord(start, 0);\r\n",
        "    matrix_mul_cpu(A,B,result_cpu,N);\r\n",
        "    cudaEventRecord(stop, 0);\r\n",
        "    cudaEventSynchronize(stop);\r\n",
        "    cudaEventElapsedTime(&gpu_time_ms, start, stop);\r\n",
        "    printf(\"cpu matrix mul 소요시간 : %f ms\\n\", gpu_time_ms);\r\n",
        "    \r\n",
        "    cudaMemPrefetchAsync(A, size, deviceId);\r\n",
        "    cudaMemPrefetchAsync(B, size, deviceId);\r\n",
        " \r\n",
        "        \r\n",
        "    dim3 threads_per_block (16, 16, 1); // A 16 x 16 block threads\r\n",
        "    dim3 number_of_blocks ((N / threads_per_block.x) + 1, (N / threads_per_block.y) + 1, 1);\r\n",
        "\r\n",
        "    /*\r\n",
        "    size_t threads;\r\n",
        "    size_t blocks;\r\n",
        "    threads = 256;\r\n",
        "    blocks = 32 * numberOfSMs;\r\n",
        "    */\r\n",
        "\r\n",
        "    cudaEventRecord(start, 0);\r\n",
        "    matrix_mul_gpu<<< number_of_blocks, threads_per_block >>> ( A, B, result_gpu, N);\r\n",
        "\r\n",
        "    cudaDeviceSynchronize();\r\n",
        "    cudaEventRecord(stop, 0);\r\n",
        "    cudaEventSynchronize(stop);\r\n",
        "    cudaEventElapsedTime(&cpu_time_ms, start, stop);\r\n",
        "    printf(\"gpu matrix mul 소요시간 : %f ms\\n\", cpu_time_ms);\r\n",
        "    cudaMemPrefetchAsync(result_gpu, size, cudaCpuDeviceId);\r\n",
        "\r\n",
        "    for (int i = 0; i < N; i++)\r\n",
        "    {\r\n",
        "        for(int j=0;j<N;j++)\r\n",
        "        {\r\n",
        "            if(result_cpu[i*N + j] != result_gpu[i*N + j])\r\n",
        "            {\r\n",
        "                chk=true;\r\n",
        "                break;\r\n",
        "            }\r\n",
        "        }\r\n",
        "        if(chk)\r\n",
        "          break;\r\n",
        "    }\r\n",
        "    if(chk)\r\n",
        "        printf(\"값 다름\");\r\n",
        "    else\r\n",
        "        printf(\"값 일치\");\r\n",
        "\r\n",
        "    cudaFree(A);\r\n",
        "    cudaFree(B);\r\n",
        "    cudaFree(result_gpu);\r\n",
        "    free(result_cpu);\r\n",
        "    return 0;\r\n",
        "}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting matrix_mul_gpu.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIAEV7ZDCkiA",
        "outputId": "ccd5552b-45e0-419b-a1cd-239e3b7c1c3d"
      },
      "source": [
        "!nvcc -o matrix_mul_gpu matrix_mul_gpu.cu -run"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu matrix mul 소요시간 : 4243.914551 ms\n",
            "gpu matrix mul 소요시간 : 8.680832 ms\n",
            "값 일치"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl09TaEOCpN9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}